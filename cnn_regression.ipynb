{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b42778f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leoeop\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyimagesearch import datasets\n",
    "from pyimagesearch import models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87b386ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\deposition_1\\optir\n",
      "./dataset\\deposition_1\\DC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1/18 [00:02<00:36,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\deposition_10\\optir\n",
      "./dataset\\deposition_10\\DC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 2/18 [00:05<00:42,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\deposition_11\\optir\n",
      "./dataset\\deposition_11\\DC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3/18 [00:08<00:42,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\deposition_12\\optir\n",
      "./dataset\\deposition_12\\DC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4/18 [00:10<00:37,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\deposition_13\\optir\n",
      "./dataset\\deposition_13\\DC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 5/18 [00:13<00:33,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\deposition_14\\optir\n",
      "./dataset\\deposition_14\\DC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 6/18 [00:15<00:29,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\deposition_15\\optir\n",
      "./dataset\\deposition_15\\DC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 7/18 [00:17<00:27,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\deposition_16\\optir\n",
      "./dataset\\deposition_16\\DC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 8/18 [00:20<00:24,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\deposition_17\\optir\n",
      "./dataset\\deposition_17\\DC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 9/18 [00:23<00:24,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\deposition_18\\optir\n",
      "./dataset\\deposition_18\\DC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 10/18 [00:25<00:20,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\deposition_2\\optir\n",
      "./dataset\\deposition_2\\DC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 11/18 [00:28<00:19,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\deposition_3\\optir\n",
      "./dataset\\deposition_3\\DC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 12/18 [00:31<00:17,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\deposition_4\\optir\n",
      "./dataset\\deposition_4\\DC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 13/18 [00:34<00:13,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\deposition_5\\optir\n",
      "./dataset\\deposition_5\\DC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 14/18 [00:37<00:10,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\deposition_6\\optir\n",
      "./dataset\\deposition_6\\DC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 15/18 [00:39<00:08,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\deposition_7\\optir\n",
      "./dataset\\deposition_7\\DC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 16/18 [00:42<00:05,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\deposition_8\\optir\n",
      "./dataset\\deposition_8\\DC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 17/18 [00:46<00:03,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\deposition_9\\optir\n",
      "./dataset\\deposition_9\\DC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:50<00:00,  2.83s/it]\n"
     ]
    }
   ],
   "source": [
    "channel_optir,channel_dc, y = datasets.load_data(data_path='./dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6c0f74d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411, 541)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_dc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9089e261",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_optir= datasets.apply_mask(channel_optir)\n",
    "channel_dc = datasets.apply_mask(channel_optir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b727b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_dc = [dc/8 for dc in channel_dc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "831d8671",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_optir = [ir/2000 for ir in channel_optir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "928a7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(imagen, greater_than= True, threshold= 4.1):\n",
    "    filtered_images = []\n",
    "    for img in imagen:\n",
    "        if greater_than:\n",
    "            img[:, np.all(img > threshold, axis = 0)]\n",
    "        else:\n",
    "            img[:, np.all(img < threshold, axis = 0)]\n",
    "        \n",
    "        filtered_images.append(img)\n",
    "    return filtered_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da949209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 1500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_dc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "615adbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_optir = filter(channel_optir, greater_than=False, threshold=4)\n",
    "channel_dc = filter(channel_dc, greater_than=False, threshold=6.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c1084f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen guardada como test.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(channel_dc[6],cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "\n",
    "print(\"Imagen guardada como test.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02edbe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= datasets.preprocessing(channel_optir,channel_dc, height_shape=200, width_shape=200)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d5f8bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Antony Cardozo\\Documents\\machine_learning\\cnn_regression\\cnn\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 440ms/step - loss: 625.0548 - val_loss: 650.6273\n",
      "Epoch 2/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 365ms/step - loss: 618.6122 - val_loss: 632.2921\n",
      "Epoch 3/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 361ms/step - loss: 606.6937 - val_loss: 600.7803\n",
      "Epoch 4/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 376ms/step - loss: 602.0793 - val_loss: 591.5565\n",
      "Epoch 5/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 360ms/step - loss: 598.9841 - val_loss: 586.9324\n",
      "Epoch 6/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 370ms/step - loss: 592.9549 - val_loss: 579.6010\n",
      "Epoch 7/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - loss: 596.9781 - val_loss: 573.7311\n",
      "Epoch 8/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 410ms/step - loss: 586.2437 - val_loss: 568.0806\n",
      "Epoch 9/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 396ms/step - loss: 583.8242 - val_loss: 565.2947\n",
      "Epoch 10/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372ms/step - loss: 568.0089 - val_loss: 557.9893\n",
      "Epoch 11/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 366ms/step - loss: 576.5247 - val_loss: 553.1713\n",
      "Epoch 12/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 363ms/step - loss: 564.8800 - val_loss: 549.6824\n",
      "Epoch 13/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 364ms/step - loss: 559.0225 - val_loss: 544.7863\n",
      "Epoch 14/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 378ms/step - loss: 547.6130 - val_loss: 530.6493\n",
      "Epoch 15/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 372ms/step - loss: 545.2687 - val_loss: 524.0795\n",
      "Epoch 16/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 372ms/step - loss: 528.6092 - val_loss: 510.8587\n",
      "Epoch 17/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 370ms/step - loss: 519.5617 - val_loss: 492.5581\n",
      "Epoch 18/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 368ms/step - loss: 513.6288 - val_loss: 482.7812\n",
      "Epoch 19/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 365ms/step - loss: 507.4022 - val_loss: 475.1159\n",
      "Epoch 20/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 364ms/step - loss: 496.4109 - val_loss: 472.0757\n",
      "Epoch 21/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 380ms/step - loss: 480.6204 - val_loss: 467.1374\n",
      "Epoch 22/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 360ms/step - loss: 479.9197 - val_loss: 463.1916\n",
      "Epoch 23/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 378ms/step - loss: 480.3627 - val_loss: 458.3871\n",
      "Epoch 24/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 364ms/step - loss: 455.0931 - val_loss: 451.9793\n",
      "Epoch 25/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 362ms/step - loss: 454.9483 - val_loss: 438.3361\n",
      "Epoch 26/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 363ms/step - loss: 448.9970 - val_loss: 433.5128\n",
      "Epoch 27/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 360ms/step - loss: 445.7542 - val_loss: 424.2320\n",
      "Epoch 28/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 362ms/step - loss: 419.4070 - val_loss: 415.3353\n",
      "Epoch 29/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 368ms/step - loss: 397.8419 - val_loss: 404.5893\n",
      "Epoch 30/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373ms/step - loss: 397.7401 - val_loss: 393.0842\n",
      "Epoch 31/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 378ms/step - loss: 396.4346 - val_loss: 366.0694\n",
      "Epoch 32/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 367ms/step - loss: 389.3318 - val_loss: 354.1974\n",
      "Epoch 33/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 365ms/step - loss: 373.8240 - val_loss: 351.2222\n",
      "Epoch 34/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372ms/step - loss: 353.8265 - val_loss: 340.4662\n",
      "Epoch 35/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 367ms/step - loss: 363.6752 - val_loss: 321.5157\n",
      "Epoch 36/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 369ms/step - loss: 354.0367 - val_loss: 313.3657\n",
      "Epoch 37/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373ms/step - loss: 339.7180 - val_loss: 318.0433\n",
      "Epoch 38/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 365ms/step - loss: 311.3865 - val_loss: 310.0025\n",
      "Epoch 39/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 383ms/step - loss: 310.2596 - val_loss: 301.1629\n",
      "Epoch 40/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 299.3300 - val_loss: 288.9457\n",
      "Epoch 41/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 371ms/step - loss: 336.2844 - val_loss: 251.8596\n",
      "Epoch 42/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 365ms/step - loss: 286.5054 - val_loss: 216.2605\n",
      "Epoch 43/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 361ms/step - loss: 267.6887 - val_loss: 183.1002\n",
      "Epoch 44/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 253.7581 - val_loss: 187.2568\n",
      "Epoch 45/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 368ms/step - loss: 247.0107 - val_loss: 181.4229\n",
      "Epoch 46/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 436ms/step - loss: 229.2474 - val_loss: 177.5410\n",
      "Epoch 47/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 493ms/step - loss: 272.9068 - val_loss: 176.5897\n",
      "Epoch 48/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 461ms/step - loss: 218.2642 - val_loss: 171.8428\n",
      "Epoch 49/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 375ms/step - loss: 218.6048 - val_loss: 165.3732\n",
      "Epoch 50/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 374ms/step - loss: 192.5390 - val_loss: 167.0771\n",
      "Epoch 51/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 364ms/step - loss: 199.8866 - val_loss: 159.9147\n",
      "Epoch 52/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 435ms/step - loss: 180.5077 - val_loss: 156.8026\n",
      "Epoch 53/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 434ms/step - loss: 203.6128 - val_loss: 162.3458\n",
      "Epoch 54/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 400ms/step - loss: 182.5535 - val_loss: 164.1303\n",
      "Epoch 55/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 384ms/step - loss: 174.4829 - val_loss: 162.6447\n",
      "Epoch 56/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 369ms/step - loss: 161.4562 - val_loss: 156.9754\n",
      "Epoch 57/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 348ms/step - loss: 188.7361 - val_loss: 149.8661\n",
      "Epoch 58/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 338ms/step - loss: 160.0707 - val_loss: 148.7313\n",
      "Epoch 59/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 338ms/step - loss: 147.6420 - val_loss: 145.7981\n",
      "Epoch 60/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 343ms/step - loss: 132.1824 - val_loss: 133.5852\n",
      "Epoch 61/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 341ms/step - loss: 136.3503 - val_loss: 124.5783\n",
      "Epoch 62/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 353ms/step - loss: 156.2996 - val_loss: 119.3685\n",
      "Epoch 63/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 345ms/step - loss: 160.9554 - val_loss: 115.7665\n",
      "Epoch 64/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 347ms/step - loss: 122.9308 - val_loss: 102.3043\n",
      "Epoch 65/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 346ms/step - loss: 113.0517 - val_loss: 95.5392\n",
      "Epoch 66/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 386ms/step - loss: 155.1906 - val_loss: 99.1792\n",
      "Epoch 67/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 370ms/step - loss: 145.4658 - val_loss: 104.1943\n",
      "Epoch 68/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375ms/step - loss: 141.6503 - val_loss: 111.9229\n",
      "Epoch 69/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 370ms/step - loss: 150.7779 - val_loss: 109.9563\n",
      "Epoch 70/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 372ms/step - loss: 110.8164 - val_loss: 102.2481\n",
      "Epoch 71/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 367ms/step - loss: 120.1486 - val_loss: 93.3542\n",
      "Epoch 72/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 366ms/step - loss: 167.2743 - val_loss: 88.2671\n",
      "Epoch 73/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 378ms/step - loss: 150.0243 - val_loss: 100.4632\n",
      "Epoch 74/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 372ms/step - loss: 97.4182 - val_loss: 97.9731\n",
      "Epoch 75/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - loss: 122.6549 - val_loss: 89.0212\n",
      "Epoch 76/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 382ms/step - loss: 125.5261 - val_loss: 84.4906\n",
      "Epoch 77/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 393ms/step - loss: 105.0404 - val_loss: 79.5829\n",
      "Epoch 78/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 450ms/step - loss: 98.4829 - val_loss: 68.4942\n",
      "Epoch 79/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 430ms/step - loss: 102.8048 - val_loss: 65.4106\n",
      "Epoch 80/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 416ms/step - loss: 89.6975 - val_loss: 69.7512\n",
      "Epoch 81/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 370ms/step - loss: 122.1380 - val_loss: 60.3189\n",
      "Epoch 82/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 417ms/step - loss: 88.2185 - val_loss: 54.1842\n",
      "Epoch 83/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 386ms/step - loss: 84.8732 - val_loss: 49.9270\n",
      "Epoch 84/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 387ms/step - loss: 88.4478 - val_loss: 49.3211\n",
      "Epoch 85/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 480ms/step - loss: 109.8792 - val_loss: 49.4653\n",
      "Epoch 86/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 392ms/step - loss: 91.8739 - val_loss: 49.8186\n",
      "Epoch 87/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 398ms/step - loss: 85.7708 - val_loss: 52.6396\n",
      "Epoch 88/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 376ms/step - loss: 103.8263 - val_loss: 57.0578\n",
      "Epoch 89/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 372ms/step - loss: 104.8766 - val_loss: 55.0581\n",
      "Epoch 90/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 447ms/step - loss: 96.4557 - val_loss: 69.4544\n",
      "Epoch 91/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 488ms/step - loss: 82.4839 - val_loss: 73.4214\n",
      "Epoch 92/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 444ms/step - loss: 94.5607 - val_loss: 64.6090\n",
      "Epoch 93/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 398ms/step - loss: 74.5434 - val_loss: 47.1852\n",
      "Epoch 94/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 390ms/step - loss: 98.7055 - val_loss: 42.2210\n",
      "Epoch 95/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 364ms/step - loss: 100.7056 - val_loss: 34.9408\n",
      "Epoch 96/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 372ms/step - loss: 97.2055 - val_loss: 26.6780\n",
      "Epoch 97/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377ms/step - loss: 95.0808 - val_loss: 23.9313\n",
      "Epoch 98/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 427ms/step - loss: 138.6085 - val_loss: 21.6247\n",
      "Epoch 99/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373ms/step - loss: 81.8015 - val_loss: 18.6668\n",
      "Epoch 100/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 366ms/step - loss: 85.6463 - val_loss: 17.2122\n",
      "Epoch 101/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375ms/step - loss: 92.3198 - val_loss: 16.9414\n",
      "Epoch 102/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 84.7748 - val_loss: 19.6514\n",
      "Epoch 103/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 64.0154 - val_loss: 22.9261\n",
      "Epoch 104/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 393ms/step - loss: 82.3092 - val_loss: 24.8828\n",
      "Epoch 105/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374ms/step - loss: 77.4604 - val_loss: 25.9382\n",
      "Epoch 106/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 358ms/step - loss: 92.4885 - val_loss: 30.4601\n",
      "Epoch 107/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 486ms/step - loss: 97.3831 - val_loss: 30.1221\n",
      "Epoch 108/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 360ms/step - loss: 85.8654 - val_loss: 30.7916\n",
      "Epoch 109/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 67.5066 - val_loss: 32.4856\n",
      "Epoch 110/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 365ms/step - loss: 93.1541 - val_loss: 42.0952\n",
      "Epoch 111/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 365ms/step - loss: 67.4953 - val_loss: 39.0607\n",
      "Epoch 112/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 364ms/step - loss: 90.2725 - val_loss: 29.1304\n",
      "Epoch 113/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 370ms/step - loss: 83.0109 - val_loss: 27.7537\n",
      "Epoch 114/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 368ms/step - loss: 83.6871 - val_loss: 31.9205\n",
      "Epoch 115/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 378ms/step - loss: 80.4069 - val_loss: 32.7706\n",
      "Epoch 116/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 375ms/step - loss: 59.2161 - val_loss: 29.0842\n",
      "Epoch 117/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 363ms/step - loss: 87.9140 - val_loss: 25.2540\n",
      "Epoch 118/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 375ms/step - loss: 72.5720 - val_loss: 22.6591\n",
      "Epoch 119/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 371ms/step - loss: 74.3011 - val_loss: 20.9680\n",
      "Epoch 120/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 384ms/step - loss: 93.9722 - val_loss: 25.2677\n",
      "Epoch 121/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 361ms/step - loss: 80.2236 - val_loss: 28.7969\n",
      "Epoch 122/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373ms/step - loss: 89.5338 - val_loss: 31.2676\n",
      "Epoch 123/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 74.7507 - val_loss: 23.8603\n",
      "Epoch 124/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 364ms/step - loss: 64.5756 - val_loss: 20.8697\n",
      "Epoch 125/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 367ms/step - loss: 92.2789 - val_loss: 19.1607\n",
      "Epoch 126/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 363ms/step - loss: 62.5359 - val_loss: 19.7374\n",
      "Epoch 127/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 90.8009 - val_loss: 23.5150\n",
      "Epoch 128/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 380ms/step - loss: 73.6898 - val_loss: 21.9489\n",
      "Epoch 129/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 364ms/step - loss: 65.0758 - val_loss: 25.9238\n",
      "Epoch 130/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 363ms/step - loss: 67.7205 - val_loss: 25.3308\n",
      "Epoch 131/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 384ms/step - loss: 72.4693 - val_loss: 26.1771\n",
      "Epoch 132/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 376ms/step - loss: 76.4191 - val_loss: 28.0531\n",
      "Epoch 133/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 365ms/step - loss: 84.9245 - val_loss: 29.5528\n",
      "Epoch 134/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 373ms/step - loss: 73.3335 - val_loss: 26.2586\n",
      "Epoch 135/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 376ms/step - loss: 71.0753 - val_loss: 23.0161\n",
      "Epoch 136/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 373ms/step - loss: 62.1601 - val_loss: 22.3779\n",
      "Epoch 137/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 369ms/step - loss: 69.2066 - val_loss: 21.2043\n",
      "Epoch 138/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373ms/step - loss: 72.5040 - val_loss: 21.4644\n",
      "Epoch 139/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 60.8852 - val_loss: 19.1925\n",
      "Epoch 140/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374ms/step - loss: 64.7009 - val_loss: 18.4056\n",
      "Epoch 141/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 63.0571 - val_loss: 17.3537\n",
      "Epoch 142/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 365ms/step - loss: 56.3742 - val_loss: 18.1437\n",
      "Epoch 143/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 390ms/step - loss: 64.0336 - val_loss: 19.7105\n",
      "Epoch 144/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 367ms/step - loss: 70.1242 - val_loss: 18.0744\n",
      "Epoch 145/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - loss: 100.7743 - val_loss: 13.9912\n",
      "Epoch 146/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 363ms/step - loss: 75.3427 - val_loss: 12.9976\n",
      "Epoch 147/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 372ms/step - loss: 71.3943 - val_loss: 12.8563\n",
      "Epoch 148/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 362ms/step - loss: 65.3149 - val_loss: 13.2843\n",
      "Epoch 149/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 366ms/step - loss: 63.0357 - val_loss: 12.5919\n",
      "Epoch 150/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 389ms/step - loss: 40.1938 - val_loss: 15.0593\n",
      "Epoch 151/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 361ms/step - loss: 57.3366 - val_loss: 14.7309\n",
      "Epoch 152/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 369ms/step - loss: 58.2097 - val_loss: 17.4752\n",
      "Epoch 153/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 363ms/step - loss: 58.7635 - val_loss: 33.0325\n",
      "Epoch 154/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 364ms/step - loss: 53.5215 - val_loss: 33.3678\n",
      "Epoch 155/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 368ms/step - loss: 68.6285 - val_loss: 17.1902\n",
      "Epoch 156/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 370ms/step - loss: 62.8126 - val_loss: 12.4118\n",
      "Epoch 157/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 59.1324 - val_loss: 11.1967\n",
      "Epoch 158/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 385ms/step - loss: 38.3477 - val_loss: 11.5682\n",
      "Epoch 159/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 365ms/step - loss: 65.9888 - val_loss: 10.7782\n",
      "Epoch 160/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 361ms/step - loss: 51.7018 - val_loss: 12.0911\n",
      "Epoch 161/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 367ms/step - loss: 53.0413 - val_loss: 13.5946\n",
      "Epoch 162/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 372ms/step - loss: 54.9527 - val_loss: 14.5122\n",
      "Epoch 163/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 374ms/step - loss: 45.0413 - val_loss: 14.9009\n",
      "Epoch 164/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 361ms/step - loss: 46.6782 - val_loss: 17.0435\n",
      "Epoch 165/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 382ms/step - loss: 59.5764 - val_loss: 15.1858\n",
      "Epoch 166/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 362ms/step - loss: 60.3910 - val_loss: 8.7065\n",
      "Epoch 167/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 365ms/step - loss: 56.4404 - val_loss: 7.4926\n",
      "Epoch 168/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 360ms/step - loss: 50.9403 - val_loss: 8.3704\n",
      "Epoch 169/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 366ms/step - loss: 41.9913 - val_loss: 8.2736\n",
      "Epoch 170/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 369ms/step - loss: 34.9172 - val_loss: 8.6782\n",
      "Epoch 171/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 74.1908 - val_loss: 8.1235\n",
      "Epoch 172/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 382ms/step - loss: 52.7775 - val_loss: 8.8604\n",
      "Epoch 173/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 361ms/step - loss: 50.5455 - val_loss: 9.4937\n",
      "Epoch 174/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 363ms/step - loss: 45.1282 - val_loss: 9.4852\n",
      "Epoch 175/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 363ms/step - loss: 67.1931 - val_loss: 9.1518\n",
      "Epoch 176/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 381ms/step - loss: 42.4853 - val_loss: 8.8269\n",
      "Epoch 177/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 365ms/step - loss: 59.3676 - val_loss: 9.2555\n",
      "Epoch 178/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 368ms/step - loss: 45.0616 - val_loss: 9.0079\n",
      "Epoch 179/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375ms/step - loss: 54.4961 - val_loss: 9.2146\n",
      "Epoch 180/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 370ms/step - loss: 56.8881 - val_loss: 9.7381\n",
      "Epoch 181/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 366ms/step - loss: 38.5977 - val_loss: 9.0479\n",
      "Epoch 182/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 367ms/step - loss: 33.4163 - val_loss: 8.1024\n",
      "Epoch 183/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 369ms/step - loss: 57.1270 - val_loss: 8.1151\n",
      "Epoch 184/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 363ms/step - loss: 50.0407 - val_loss: 7.8426\n",
      "Epoch 185/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 370ms/step - loss: 59.4859 - val_loss: 7.8470\n",
      "Epoch 186/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 369ms/step - loss: 42.1781 - val_loss: 10.1402\n",
      "Epoch 187/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 366ms/step - loss: 39.2906 - val_loss: 13.0374\n",
      "Epoch 188/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - loss: 55.7423 - val_loss: 15.6971\n",
      "Epoch 189/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 45.1701 - val_loss: 19.4150\n",
      "Epoch 190/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 371ms/step - loss: 46.6402 - val_loss: 24.0615\n",
      "Epoch 191/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 367ms/step - loss: 36.5351 - val_loss: 33.1478\n",
      "Epoch 192/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 368ms/step - loss: 39.4698 - val_loss: 28.2525\n",
      "Epoch 193/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 378ms/step - loss: 51.5009 - val_loss: 28.5472\n",
      "Epoch 194/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 386ms/step - loss: 51.2494 - val_loss: 26.9497\n",
      "Epoch 195/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375ms/step - loss: 44.5747 - val_loss: 20.9504\n",
      "Epoch 196/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 363ms/step - loss: 62.3659 - val_loss: 19.3398\n",
      "Epoch 197/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 376ms/step - loss: 45.4036 - val_loss: 24.7329\n",
      "Epoch 198/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 365ms/step - loss: 44.9389 - val_loss: 19.1140\n",
      "Epoch 199/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 362ms/step - loss: 49.6001 - val_loss: 13.8009\n",
      "Epoch 200/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 392ms/step - loss: 40.6323 - val_loss: 11.1699\n",
      "Epoch 201/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 363ms/step - loss: 54.5901 - val_loss: 9.5180\n",
      "Epoch 202/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 363ms/step - loss: 49.4779 - val_loss: 8.2254\n",
      "Epoch 203/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 369ms/step - loss: 41.3668 - val_loss: 7.9828\n",
      "Epoch 204/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 372ms/step - loss: 40.7564 - val_loss: 7.6186\n",
      "Epoch 205/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 363ms/step - loss: 52.7633 - val_loss: 7.3146\n",
      "Epoch 206/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 376ms/step - loss: 46.3321 - val_loss: 6.5190\n",
      "Epoch 207/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 365ms/step - loss: 33.1138 - val_loss: 6.1268\n",
      "Epoch 208/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 383ms/step - loss: 41.2813 - val_loss: 5.9051\n",
      "Epoch 209/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 384ms/step - loss: 44.3394 - val_loss: 5.6711\n",
      "Epoch 210/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 370ms/step - loss: 48.9368 - val_loss: 5.1951\n",
      "Epoch 211/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 364ms/step - loss: 42.0730 - val_loss: 5.2893\n",
      "Epoch 212/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 369ms/step - loss: 38.5653 - val_loss: 5.0476\n",
      "Epoch 213/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 35.8892 - val_loss: 4.7938\n",
      "Epoch 214/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 56.5030 - val_loss: 4.6888\n",
      "Epoch 215/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 380ms/step - loss: 54.0889 - val_loss: 4.6854\n",
      "Epoch 216/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 367ms/step - loss: 53.8514 - val_loss: 4.7199\n",
      "Epoch 217/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 371ms/step - loss: 34.9657 - val_loss: 4.6810\n",
      "Epoch 218/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375ms/step - loss: 38.1999 - val_loss: 4.7800\n",
      "Epoch 219/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 382ms/step - loss: 53.0517 - val_loss: 4.8134\n",
      "Epoch 220/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 370ms/step - loss: 49.0290 - val_loss: 4.7315\n",
      "Epoch 221/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 368ms/step - loss: 50.9727 - val_loss: 4.9500\n",
      "Epoch 222/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 403ms/step - loss: 41.5465 - val_loss: 5.1763\n",
      "Epoch 223/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372ms/step - loss: 41.5917 - val_loss: 5.3109\n",
      "Epoch 224/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 364ms/step - loss: 54.8548 - val_loss: 4.7120\n",
      "Epoch 225/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 372ms/step - loss: 33.5688 - val_loss: 4.4779\n",
      "Epoch 226/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - loss: 33.4352 - val_loss: 4.4868\n",
      "Epoch 227/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 377ms/step - loss: 37.6180 - val_loss: 4.4352\n",
      "Epoch 228/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374ms/step - loss: 36.6835 - val_loss: 4.4235\n",
      "Epoch 229/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 370ms/step - loss: 38.0399 - val_loss: 4.3315\n",
      "Epoch 230/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 391ms/step - loss: 43.4022 - val_loss: 4.4573\n",
      "Epoch 231/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 365ms/step - loss: 39.8500 - val_loss: 5.1062\n",
      "Epoch 232/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - loss: 48.6758 - val_loss: 5.6247\n",
      "Epoch 233/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 378ms/step - loss: 33.7588 - val_loss: 6.3927\n",
      "Epoch 234/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 365ms/step - loss: 29.2071 - val_loss: 6.1109\n",
      "Epoch 235/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 378ms/step - loss: 42.7310 - val_loss: 5.7170\n",
      "Epoch 236/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 383ms/step - loss: 44.2159 - val_loss: 5.6321\n",
      "Epoch 237/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 369ms/step - loss: 46.2196 - val_loss: 6.1554\n",
      "Epoch 238/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 383ms/step - loss: 36.0691 - val_loss: 7.3268\n",
      "Epoch 239/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 364ms/step - loss: 42.5695 - val_loss: 7.4293\n",
      "Epoch 240/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 36.7535 - val_loss: 7.1724\n",
      "Epoch 241/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - loss: 53.9448 - val_loss: 6.2709\n",
      "Epoch 242/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 370ms/step - loss: 44.4327 - val_loss: 5.6683\n",
      "Epoch 243/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 378ms/step - loss: 45.6415 - val_loss: 5.6007\n",
      "Epoch 244/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 367ms/step - loss: 37.4934 - val_loss: 5.8180\n",
      "Epoch 245/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 370ms/step - loss: 39.8661 - val_loss: 6.2094\n",
      "Epoch 246/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 43.9038 - val_loss: 6.1608\n",
      "Epoch 247/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 365ms/step - loss: 35.0375 - val_loss: 5.8092\n",
      "Epoch 248/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 40.8172 - val_loss: 5.5339\n",
      "Epoch 249/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 363ms/step - loss: 48.7183 - val_loss: 5.5376\n",
      "Epoch 250/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 370ms/step - loss: 33.5519 - val_loss: 5.3556\n",
      "Epoch 251/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 465ms/step - loss: 34.7198 - val_loss: 5.2383\n",
      "Epoch 252/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 367ms/step - loss: 50.7664 - val_loss: 5.5454\n",
      "Epoch 253/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 382ms/step - loss: 56.3363 - val_loss: 5.8882\n",
      "Epoch 254/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 371ms/step - loss: 29.2655 - val_loss: 5.9953\n",
      "Epoch 255/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 365ms/step - loss: 53.4592 - val_loss: 5.8260\n",
      "Epoch 256/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 376ms/step - loss: 54.8575 - val_loss: 5.7336\n",
      "Epoch 257/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 366ms/step - loss: 30.5678 - val_loss: 6.2941\n",
      "Epoch 258/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 372ms/step - loss: 44.1137 - val_loss: 6.6084\n",
      "Epoch 259/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 369ms/step - loss: 39.2101 - val_loss: 6.6107\n",
      "Epoch 260/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 379ms/step - loss: 32.6967 - val_loss: 6.4870\n",
      "Epoch 261/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 44.7848 - val_loss: 6.2857\n",
      "Epoch 262/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372ms/step - loss: 40.4435 - val_loss: 6.2695\n",
      "Epoch 263/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 362ms/step - loss: 42.7931 - val_loss: 6.2282\n",
      "Epoch 264/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 363ms/step - loss: 34.4020 - val_loss: 6.5812\n",
      "Epoch 265/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 366ms/step - loss: 38.7124 - val_loss: 6.6365\n",
      "Epoch 266/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 368ms/step - loss: 33.1800 - val_loss: 6.6858\n",
      "Epoch 267/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 376ms/step - loss: 35.0441 - val_loss: 6.7673\n",
      "Epoch 268/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 361ms/step - loss: 36.0023 - val_loss: 6.8094\n",
      "Epoch 269/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 365ms/step - loss: 24.8440 - val_loss: 6.4548\n",
      "Epoch 270/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 366ms/step - loss: 35.4384 - val_loss: 6.2764\n",
      "Epoch 271/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 373ms/step - loss: 35.9105 - val_loss: 6.3149\n",
      "Epoch 272/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375ms/step - loss: 35.8572 - val_loss: 6.4909\n",
      "Epoch 273/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 375ms/step - loss: 35.5548 - val_loss: 6.7657\n",
      "Epoch 274/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 369ms/step - loss: 31.0468 - val_loss: 7.2778\n",
      "Epoch 275/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 37.1367 - val_loss: 7.6430\n",
      "Epoch 276/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373ms/step - loss: 35.9009 - val_loss: 7.1740\n",
      "Epoch 277/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 369ms/step - loss: 45.1272 - val_loss: 7.7282\n",
      "Epoch 278/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 371ms/step - loss: 46.1630 - val_loss: 8.1892\n",
      "Epoch 279/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 366ms/step - loss: 30.2734 - val_loss: 8.2764\n",
      "Epoch 280/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 369ms/step - loss: 43.1668 - val_loss: 7.6164\n",
      "Epoch 281/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 364ms/step - loss: 28.9647 - val_loss: 6.0947\n",
      "Epoch 282/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 368ms/step - loss: 48.1875 - val_loss: 6.0150\n",
      "Epoch 283/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 369ms/step - loss: 50.5672 - val_loss: 5.6537\n",
      "Epoch 284/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 373ms/step - loss: 35.9042 - val_loss: 5.5440\n",
      "Epoch 285/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 369ms/step - loss: 38.0839 - val_loss: 5.3439\n",
      "Epoch 286/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 368ms/step - loss: 32.2667 - val_loss: 5.6352\n",
      "Epoch 287/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 362ms/step - loss: 39.8917 - val_loss: 6.2946\n",
      "Epoch 288/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 365ms/step - loss: 37.8432 - val_loss: 7.8737\n",
      "Epoch 289/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 382ms/step - loss: 30.5593 - val_loss: 8.7470\n",
      "Epoch 290/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375ms/step - loss: 37.0647 - val_loss: 8.3221\n",
      "Epoch 291/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374ms/step - loss: 33.7563 - val_loss: 7.8173\n",
      "Epoch 292/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 369ms/step - loss: 39.2720 - val_loss: 7.9622\n",
      "Epoch 293/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 371ms/step - loss: 40.0135 - val_loss: 8.0324\n",
      "Epoch 294/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 373ms/step - loss: 36.5299 - val_loss: 7.7160\n",
      "Epoch 295/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 364ms/step - loss: 35.6144 - val_loss: 8.2256\n",
      "Epoch 296/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - loss: 38.6436 - val_loss: 9.7185\n",
      "Epoch 297/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 364ms/step - loss: 34.1215 - val_loss: 10.5398\n",
      "Epoch 298/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 366ms/step - loss: 35.0091 - val_loss: 9.9307\n",
      "Epoch 299/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 363ms/step - loss: 31.6155 - val_loss: 8.4837\n",
      "Epoch 300/300\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 361ms/step - loss: 42.5529 - val_loss: 7.7299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x245140d3710>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.create_cnn(200, 200, 2, regress=True)\n",
    "opt = Adam( learning_rate=1e-3, decay=1e-3 / 200)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=opt)\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "model.fit(x=X_train, y=y_train,validation_data=(X_test, y_test), epochs=300, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ca1f145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] predicting house prices...\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the testing data\n",
    "print(\"[INFO] predicting house prices...\")\n",
    "preds = model.predict(X_test)\n",
    "# compute the difference between the *predicted* house prices and the\n",
    "# *actual* house prices, then compute the percentage difference and\n",
    "# the absolute percentage difference\n",
    "diff = preds.flatten() - y_test\n",
    "percentDiff = (diff / y_test) * 100\n",
    "absPercentDiff = np.abs(percentDiff)\n",
    "# compute the mean and standard deviation of the absolute percentage\n",
    "# difference\n",
    "mean = np.mean(absPercentDiff)\n",
    "std = np.std(absPercentDiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b458130f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.46385447  4.89423616 17.7122048   7.42954527 10.7228152  12.34961423\n",
      "  5.28092818 17.3697131  20.42179108 10.82183838 11.92950335 14.45368767\n",
      " 15.11309624  0.41677952 11.55989387  8.76024791  7.08054701 16.85520172\n",
      " 16.94565773  0.72603226  6.47330718  1.91184824  2.2619009   7.49954811\n",
      "  8.70747884  5.47644297  3.76439461  1.63322796  3.98105894 12.80612212\n",
      " 10.80693245  9.05077616  9.02335094 19.07815933  4.53829399 19.7470665 ]\n",
      "[-1.63915634 -1.37038612 -4.95941734 -2.08027267 -3.21684456  2.71691513\n",
      "  1.1618042  -4.86351967 -6.12653732 -3.24655151  2.62449074  2.89073753\n",
      "  3.02261925 -0.10002708  2.54317665 -2.45286942 -1.69933128  3.37104034\n",
      "  3.38913155  0.1597271  -1.42412758  0.42060661 -0.54285622 -1.94988251\n",
      " -2.61224365 -1.31434631 -0.9787426  -0.35931015 -1.1146965  -3.32959175\n",
      "  2.16138649 -2.71523285 -2.34607124 -5.34188461 -1.17995644  3.9494133 ]\n",
      "9.529641593394004\n"
     ]
    }
   ],
   "source": [
    "print(absPercentDiff)\n",
    "print(diff)\n",
    "print(mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2895467a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 28, 28, 28, 30, 22, 22, 28, 30, 30, 22, 20, 20, 24, 22, 28, 24,\n",
       "       20, 20, 22, 22, 22, 24, 26, 30, 24, 26, 22, 28, 26, 20, 30, 26, 28,\n",
       "       26, 20])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
